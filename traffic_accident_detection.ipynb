{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb66c832-fe71-4393-a666-aacb087ad3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import einops\n",
    "import video_tools\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac97530-c5d0-4643-98f5-6e02aff7385a",
   "metadata": {},
   "source": [
    "Below I'll show the GIF of the filtered frames. I simulate a \"collision\" of my hands in the test video that I'm using. My hands collide at around timestamp 1500 msec. The code then extract a set of frames which include the exact frame at timestamp 1500 msec so we have the frame at the exact moment when my hand \"collided\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a3b82-86ef-426f-ba64-03e224ef9c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example frames in GIF\n",
    "\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "\n",
    "tmp_dir = './tmp'\n",
    "pathlib.Path(tmp_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "video_filepath = 'data/traffic_accident_videos/videos/traffic_accident_1.mp4'\n",
    "gif_out_file_path = f'{tmp_dir}/test.gif'\n",
    "\n",
    "frame_index_sequences, labels = video_tools.get_frame_indexes_surrounding_event(video_filepath, event_timestamp_millis=5790, sequence_length=11, frame_step=10)\n",
    "vid_frames = video_tools.get_image_frames(video_filepath, frame_index_sequences)\n",
    "\n",
    "imageio.mimsave(gif_out_file_path, vid_frames[5], fps=10)\n",
    "Image(filename=gif_out_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af2a9b-fbb7-4ba2-8675-8286dcf5fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format image frame before input to model\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "def format_image_frame(frame):\n",
    "    frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "    frame = tf.image.resize_with_pad(frame, HEIGHT, WIDTH)\n",
    "    \n",
    "    return frame.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d453b6a-439c-4edc-89a4-35633a726ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "labels_file_path = './data/traffic_accident_videos/labels.csv'\n",
    "videos_dir_path = './data/traffic_accident_videos/videos/'\n",
    "batch_size = 20\n",
    "sequence_length = 15\n",
    "frame_step_size = 5\n",
    "min_proportion_of_after_event_frames = 0.3\n",
    "max_proportion_of_after_event_frames = 0.8\n",
    "num_sequences_for_no_event_videos = 30\n",
    "\n",
    "frame_generator = video_tools.FrameGenerator(videos_dir_path=videos_dir_path,\n",
    "                                             labels_file_path=labels_file_path,\n",
    "                                             sequence_length=sequence_length,\n",
    "                                             frame_step_size=frame_step_size,\n",
    "                                             min_proportion_of_after_event_frames=min_proportion_of_after_event_frames,\n",
    "                                             max_proportion_of_after_event_frames=max_proportion_of_after_event_frames,\n",
    "                                             num_sequences_for_no_event_videos=num_sequences_for_no_event_videos,\n",
    "                                             format_frame_fn=format_image_frame)\n",
    "\n",
    "output_signature = (tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32), tf.TensorSpec(shape=(), dtype=tf.uint8))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(frame_generator, output_signature=output_signature)\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE).cache().shuffle(buffer_size=1000, reshuffle_each_iteration=True).repeat().batch(batch_size)\n",
    "\n",
    "# test\n",
    "ratio_of_ones = []\n",
    "\n",
    "for frames, labels in train_ds.take(10):\n",
    "    assert frames.shape == (batch_size, sequence_length, HEIGHT, WIDTH, 3)\n",
    "    assert labels.shape == (batch_size,)\n",
    "    ratio_of_ones.append(np.mean(labels))\n",
    "\n",
    "print('All tests OK.')\n",
    "print(f'Class balance evaluation: {np.mean(ratio_of_ones)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91355bc1-bc65-4cba-8479-c1df5869eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2Plus1D(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.seq = keras.Sequential([\n",
    "            keras.layers.Conv3D(filters=filters,\n",
    "                          kernel_size=(1, kernel_size[1], kernel_size[2]),\n",
    "                          padding=padding),\n",
    "            keras.layers.Conv3D(filters=filters,\n",
    "                          kernel_size=(kernel_size[0], 1, 1),\n",
    "                          padding=padding)\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "    \n",
    "class ResidualMain(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super().__init__()\n",
    "        self.seq = keras.Sequential([\n",
    "            Conv2Plus1D(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same'),\n",
    "            keras.layers.LayerNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            Conv2Plus1D(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same'),\n",
    "            keras.layers.LayerNormalization()\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "class Project(keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.seq = keras.Sequential([\n",
    "            keras.layers.Dense(units),\n",
    "            keras.layers.LayerNormalization()\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "    \n",
    "def add_residual_block(input, filters, kernel_size):\n",
    "    out = ResidualMain(filters=filters, kernel_size=kernel_size)(input)\n",
    "    \n",
    "    res = input\n",
    "    if out.shape[-1] != input.shape[-1]:\n",
    "        res = Project(out.shape[-1])(res)\n",
    "    \n",
    "    return keras.layers.add([res, out])\n",
    "\n",
    "class ResizeVideo(keras.layers.Layer):\n",
    "    def __init__(self, height, width):\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = keras.layers.Resizing(self.height, self.width)\n",
    "        \n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c',\n",
    "                                  t=old_shape['t'])\n",
    "        \n",
    "        return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc11a3e-1a9d-4f1b-b3c5-ec70867378c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "input = layers.Input(shape=(sequence_length, HEIGHT, WIDTH, 3))\n",
    "x = input\n",
    "x = Conv2Plus1D(filters=16, kernel_size=(3, 7, 7), padding='same')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = ResizeVideo(HEIGHT//2, WIDTH//2)(x)\n",
    "\n",
    "x = add_residual_block(x, filters=16, kernel_size=(3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT//4, WIDTH//4)(x)\n",
    "\n",
    "x = add_residual_block(x, filters=32, kernel_size=(3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT//8, WIDTH//8)(x)\n",
    "\n",
    "x = add_residual_block(x, filters=64, kernel_size=(3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT//16, WIDTH//16)(x)\n",
    "\n",
    "x = add_residual_block(x, filters=128, kernel_size=(3, 3, 3))\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling3D()(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(1)(x)\n",
    "\n",
    "model = keras.Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e333934-0aa2-4646-b6d0-19c455b8c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb56e1e7-5b4f-41a7-9cea-43bb6149646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0fdee5-8bbe-4d25-95c4-e53bf4031320",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./training_checkpoint/checkpoint\"\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor='loss',\n",
    "                                                 mode='min',\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "history = model.fit(x=train_ds,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=50,\n",
    "                    callbacks=[cp_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
